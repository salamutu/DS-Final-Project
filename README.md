# DS-Final-Project

#### Also in Jupyter Notebook

### Introduction
Our project focused on analyzing the “Crime Incidents in 2024” dataset, which is a detailed record of crimes reported to the Maryland Police Department and made available on Data.gov. Entries in the dataset include the type of offense, date, and time it occurred, and its location. Some entries also include information about the status of the crime and outcomes of the incident. We aimed to answer the following question: What factors affect the type of offense committed? Using variables such as time and date, location, and other available information, we gained insight into the relationships between the context and the crime committed. Understanding these relationships can help develop strategies to increase public safety and allocate resources more effectively.

### Overview of methods
First, we cleaned up the data to improve usability and clarify the feature labels. A detailed list explaining the labels can be found under “Feature Description” in the main file. For example, “CCN” means criminal complaint number, a unique identifier assigned by MPD to each incident. We dropped features we did not intend to use, such as block and report date, were dropped, and dates and times were converted to a standard 24-hour clock for readability. Some features were renamed to clarify what they are, such as “X” to “x_coordinate”.
Next, we did an exploratory data analysis (EDA), creating graphs to find what crimes, locations, and times were dominant in the dataset and pointed us towards what might be significant. The majority of crimes were theft and nonviolent, and committed during the day (evening shift followed by daytime). We created both a heatmap and a Kernel Density Estimate (KDE) plot to represent the crime density, using the x and y coordinates as a pseudo-map. Both showed a clear center of where most crime occurs, with increased crime surrounding. The KDE plot more clearly revealed the smaller centers of crime, but we retained both visualizations as each offers useful perspectives depending on the context. Following the EDA, we ran several models to learn about the data. A more in-depth explanation of the models we used can be found below.

### Models
The first model we used was a logistic regression, predicting whether the crime was theft or not. Offenses were grouped into theft and non-theft, and categorical features were one-hot encoded. Using LogisticRegression from sklearn and a 70/30 training-testing split, logistic regression was able to predict theft or not with an overall accuracy of 68%. The precision for theft crimes was high, but non-theft crimes had a low precision and many were false positives. Overall, the logistic regression model wasn’t the best for our data and lacked accuracy in comparison to others.


The next model we tried was XGboost. The target variable “neighborhood cluster” was encoded and features were converted to dummy variables. With and 80/20 training testing split, the XGBClassifier from sklearn was run and identified the y and x coordinates as the most important features with 98% accuracy. As these are the obvious answers in predicting neighborhood, it is important to note the next three most important features are offense theft/other, offense theft/auto, and day shift. This suggests that the type of crime and time of day are characteristic to the specific neighborhoods.

We then ran a grid search, looking to find the best hyper parameters to optimize XGBoost. It found the best parameters were max depth 5, learning rate 0.1, n estimators 100, sumsample 1, and colsample_bytree 1. Using these, the XGBoost model was again able to achieve 98% accuracy for both testing, and cross-validated mean. The training and testing accuracy remained close, which suggests that overfitting was reduced.


The last model we used was a random forest. First, new variables were created that were easier to work with, such as grouping crimes that were not common and converting times to extract the hour. The initial random forest was made using sklearn, using all variables with no max depth and 100 trees. With a train/test split of 70/30, it was able to achieve an accuracy of 92.2%. It revealed that method was the most important predictor in if a crime was theft or not. Using the grid search, another random forest model was run using 500 trees, 3 features per split, and a max depth of 20 which slightly improved accuracy to 92.5%. In addition to method, it revealed that duration and start time are also important in predicting theft.


Overall, from the models used we can conclude that geographical location, timing, and method of crime are most important to predicting the type of crime committed when simplified to theft vs. not theft. From XGBoost, we learned that different neighborhoods have unique patterns in the types and times of crimes committed and from the random forest we were able to extract that duration is important as well. Method as a predictor seems strong in the random forest model, but more exploration may be needed to determine its importance as many thefts list “other” as a method, as opposed to a specific weapon. Perhaps this means they commonly used no weapon, but it cannot be concluded from the data at hand. Additionally, method may not be super useful in real applications like allocating police presence the same way geographical location and time of day such crimes get committed are.


### Limitations and Future Work
While the models provided valuable insights, several limitations should be noted. First, the dataset only included reported crimes, which introduces potential reporting bias. So certain offenses or areas might be underreported or overrepresented. Additionally, many crimes had missing or vague feature entries (such as “method” being listed as “other”), limiting the predictive power of certain models.
Our analysis also simplified offenses into broad categories like theft vs. non-theft to make classification more feasible. However, crimes are diverse and complex. A future extension of this work could involve multi-class classification, predicting specific types of offenses rather than a binary split. 
Furthermore, while location and time were strong predictors, these are not easily adjustable factors. Future work could focus on building models that are more actionable for crime prevention efforts. For example, by identifying early warning signs based on method or duration rather than solely on geographic clustering. 


### Conclusion
Through cleaning, exploratory data analysis, and multiple machine learning models, we gained meaningful insights into crime patterns within the 2024 Maryland dataset. We found that geographic location, time of day, and crime method are key factors associated with different types of offenses. XGBoost and Random Forest models performed particularly well, with XGBoost excelling at location-based predictions and Random Forest identifying time and method as critical features. These results suggest that targeted, data-driven strategies could be developed to allocate resources more efficiently and enhance public safety efforts. Future work could build on this foundation by incorporating more nuanced crime categories and exploring external variables to enrich predictive modeling. 
